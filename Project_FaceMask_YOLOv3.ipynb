{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66f2jiRvKyUv",
        "outputId": "dbd42fc1-c3ac-40cc-ae93-6afae157ae5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "MOUNTPOINT = '/content/gdrive'\n",
        "\n",
        "DATADIR = os.path.join(MOUNTPOINT, 'My Drive', 'Project_Face_Mask')\n",
        "DATADIR_annotations = os.path.join(DATADIR, 'Annotations')\n",
        "DATADIR_annotations_train = os.path.join(DATADIR_annotations, 'train')\n",
        "DATADIR_annotations_test = os.path.join(DATADIR_annotations, 'test')\n",
        "DATADIR_train = os.path.join(DATADIR, 'train')\n",
        "DATADIR_test = os.path.join(DATADIR, 'test')\n",
        "\n",
        "drive.mount(MOUNTPOINT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "TukfX4VBddwX"
      },
      "outputs": [],
      "source": [
        "import xml.etree.ElementTree as ET\n",
        "import pandas as pd\n",
        "import lxml\n",
        "import os\n",
        "import matplotlib.image as mpimg\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf \n",
        "import numpy as np "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQtmbEiC_IrY"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "EZ802Cx4-0Nd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5582dcde-616c-4699-dd9b-b26260df1774"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<_LoadDataset element_spec=(TensorSpec(shape=(416, 416, 3), dtype=tf.uint8, name=None), TensorSpec(shape=(), dtype=tf.int32, name=None), RaggedTensorSpec(TensorShape([None]), tf.int32, 0, tf.int64))>\n"
          ]
        }
      ],
      "source": [
        "ds_train = tf.data.experimental.load(os.path.join(DATADIR, 'train_ds_yolov3'))\n",
        "\n",
        "print(ds_train)\n",
        "\n",
        "ds_train = ds_train.map(lambda img, target, bbox: (tf.cast(img, tf.float32), target, bbox))\n",
        "ds_train = ds_train.map(lambda img, target, bbox: ((img/128.)-1.,target, bbox))\n",
        "ds_train = ds_train.map(lambda img, target, bbox: (tf.expand_dims(img, axis = 0), target, bbox))\n",
        "#ds_train = ds_train.map(lambda img, target, bbox: (img, tf.cast(target, tf.float), bbox))\n",
        "ds_train = ds_train.map(lambda img, target, bbox: (img, tf.one_hot(target, 3), bbox))\n",
        "ds_train = ds_train.shuffle(100)\n",
        "#ds_train = ds_train.batch(10)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "OPgS-XKJ9PWO"
      },
      "outputs": [],
      "source": [
        "\"\"\"Anchor-Boxes for the predictions on the 3 different Shapes\"\"\"\n",
        "anchor = [(10, 13), (16, 30), (33, 23),\n",
        "            (30, 61), (62, 45), (59, 119),\n",
        "            (116, 90), (156, 198), (373, 326)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "rvEiQHD9PXQ6"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Pads the Input of the Tensor with Constant values\n",
        "\"\"\"\n",
        "def constant_padding(tensor, kernel_size):\n",
        "  padding = kernel_size - 1\n",
        "  padding_vorne = padding // 2\n",
        "  padding_hinten = padding - padding_vorne\n",
        "\n",
        "  padding = tf.constant([[0,0],[padding_vorne, padding_hinten], [padding_vorne, padding_hinten],[0,0]])\n",
        "\n",
        "  input_padded = tf.pad(tensor, padding)\n",
        "  return input_padded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "qD-5SavFHmp2"
      },
      "outputs": [],
      "source": [
        "\n",
        "\"\"\"Hyperparameter for the Batch-Normalization and Leaky-RELU Activation of the Model\"\"\"\n",
        "batch_normalization_epsilon = 1e-05\n",
        "batch_normalization_momentum = 0.9\n",
        "leaky_relu_alpha = 0.1\n",
        "\"\"\"\n",
        "A Convolutional Block of the Darknet53-Framework. It Consists of a normal Conv2D-Layer, followed by a BatchNormalization and a Leaky-Relu Activation\n",
        "Parameter:\n",
        "filter = Amount of Filters for Convolution \n",
        "Kernel_size = Kernel-Size for Convolution\n",
        "\n",
        "\"\"\"\n",
        "class Conv_Block(tf.keras.layers.Layer):\n",
        "\n",
        "  def __init__(self, filter, kernel_size, strides = 1):\n",
        "    self.padding = ('same' if strides == 1 else 'valid')\n",
        "    self.kernel_size = kernel_size\n",
        "    super(Conv_Block, self).__init__()\n",
        "    self.layers = [\n",
        "    tf.keras.layers.Conv2D(filter, kernel_size = self.kernel_size, padding = self.padding, activation = 'linear', strides = strides),\n",
        "    tf.keras.layers.BatchNormalization(axis = 3, momentum = batch_normalization_momentum, epsilon = batch_normalization_epsilon,scale = True),\n",
        "    tf.keras.layers.LeakyReLU(alpha = 0.1)\n",
        "    ]\n",
        "\n",
        "  @tf.function\n",
        "  def call(self, input):\n",
        "    if self.padding == 'valid':\n",
        "      input = constant_padding(input, self.kernel_size)\n",
        "    out = input\n",
        "    for layer in self.layers: \n",
        "      out = layer(out)\n",
        "  \n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "uc1LKjBdKoyL"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "A Residual Block consisting of 2 Convolutional Blocks and a Skip-Connection and Addition \n",
        "\n",
        "\n",
        "\"\"\"\n",
        "class Residual_Block(tf.keras.layers.Layer):\n",
        "  def __init__(self, filter):\n",
        "      super(Residual_Block, self).__init__()\n",
        "     \n",
        "      self.conv1 = Conv_Block(filter, 1,1)\n",
        "      self.conv2 = Conv_Block(filter * 2, 3,1)\n",
        "      self.addition_layer = tf.keras.layers.Add()\n",
        "  \n",
        "      \n",
        "\n",
        "  @tf.function\n",
        "  def call(self, input):\n",
        "    \n",
        "    out = self.conv1(input)\n",
        "    out = self.conv2(out)\n",
        "    out = self.addition_layer([input, out])\n",
        "   \n",
        "    \n",
        "\n",
        "    return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "V_DdOPBLPzCj"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "A Class of n Residual-Blocks\n",
        "Parameters:\n",
        "filters: Convolution-Filters\n",
        "n : Amount of Residual Blocks Stacked on top of each other \n",
        "\"\"\"\n",
        "class Stacked_Residual_Block(tf.keras.layers.Layer):\n",
        "  def __init__(self, filter, n):\n",
        "      super(Stacked_Residual_Block, self).__init__()\n",
        "      self.blocks = []\n",
        "      for i in range(n):\n",
        "        self.blocks.append(Residual_Block(filter))\n",
        "      \n",
        "\n",
        "  @tf.function\n",
        "  def call(self, input):\n",
        "    out = input\n",
        "    for block in self.blocks:\n",
        "      out = block(out)\n",
        "\n",
        "    return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "0-K6YOgIGy3y"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "The Darknet53 Model. This acts as the Feature-Extractor of the Yolo-V3-Model\n",
        "The Model Outputs feature Maps on 3 different Routes, that are later used in the Predictions on the 3 Scales \n",
        "\"\"\"\n",
        "class darknet53(tf.keras.Model):\n",
        "\n",
        "  def __init__(self):\n",
        "    super(darknet53, self).__init__()\n",
        " \n",
        "    self.conv_1 = Conv_Block(32,3,1)\n",
        "    self.conv_2 = Conv_Block(64,3,2)\n",
        "    self.res_1 = Stacked_Residual_Block(32, 1)\n",
        "    self.conv_3 = Conv_Block(128,3,2)\n",
        "    self.res_2 = Stacked_Residual_Block(64, 2)\n",
        "    self.conv_4 = Conv_Block(256,3,2)\n",
        "    self.res_3 = Stacked_Residual_Block(128, 8)\n",
        "    self.conv_5 = Conv_Block(512,3,2)\n",
        "    self.res_4 = Stacked_Residual_Block(256, 8)\n",
        "    self.conv_6 = Conv_Block(1024,3,2)\n",
        "    self.res_5 = Stacked_Residual_Block(512, 4)\n",
        "    \n",
        "  @tf.function\n",
        "  def call(self, input):\n",
        "\n",
        "    out = self.conv_1(input)\n",
        "    out = self.conv_2(out)   \n",
        "    out = self.res_1(out)   \n",
        "    out = self.conv_3(out)   \n",
        "    out = self.res_2(out)   \n",
        "    out = self.conv_4(out)   \n",
        "    out = self.res_3(out)  \n",
        "    route3 = out\n",
        "    out = self.conv_5(out)  \n",
        "    out = self.res_4(out)   \n",
        "    route2 = out\n",
        "    out = self.conv_6(out)   \n",
        "    route1 = self.res_5(out)       \n",
        "\n",
        "    return route1, route2, route3\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "yQxUahGS9a5w"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "A Block of 6 Convolutional Layers. \n",
        "\n",
        "\"\"\"\n",
        "\n",
        "class yolo_conv_block(tf.keras.layers.Layer):\n",
        "  def __init__(self, filters):\n",
        "      super(yolo_conv_block, self).__init__()\n",
        "     \n",
        "      self.conv1 = Conv_Block(filters, 1)\n",
        "      self.conv2 = Conv_Block(filters * 2, 3)\n",
        "      self.conv3 = Conv_Block(filters, 1)\n",
        "      self.conv4 = Conv_Block(filters * 2, 3)\n",
        "      self.conv5 = Conv_Block(filters, 1)\n",
        "      self.conv6 = Conv_Block(filters * 2, 3)\n",
        "\n",
        "    \n",
        "      \n",
        "\n",
        "  @tf.function\n",
        "  def call(self, input):\n",
        "    out = self.conv1(input)\n",
        "    out = self.conv2(out)\n",
        "    out = self.conv3(out)\n",
        "    out = self.conv4(out)\n",
        "    out = self.conv5(out)\n",
        "    reroute = out\n",
        "    out = self.conv6(out)\n",
        "\n",
        "    return out, reroute"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "IAr356tt81FO"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Output Layer of the Yolo Model. This Layer detects Feature-Maps at 3 different Scales, in our case (13,13) (26,26) and (52,52)\n",
        "\"\"\"\n",
        "class yolo_detection_layer(tf.keras.layers.Layer):\n",
        "  \n",
        "  def __init__(self, anchors, image_size = (416,416)):\n",
        "      super(yolo_detection_layer, self).__init__()\n",
        "      '''\n",
        "      #Filters = \n",
        "        Menge_Anchor(Boxen) * (5 (Box-Koordinaten und Convidence)+ Menge an Klassen (Bei uns 3 (mit oder ohne Maske)))\n",
        "      '''\n",
        "      self.anchors = anchors\n",
        "      self.image_size = image_size\n",
        "      \"\"\"1*1 Convolution - Bottleneck-Layer to get right size of feature map\"\"\"\n",
        "      self.conv1 = tf.keras.layers.Conv2D(filters= 3 * (5+3),kernel_size = 1, strides = 1)\n",
        "\n",
        "    \n",
        "\n",
        "      \n",
        "    \n",
        "      \n",
        "\n",
        "  @tf.function\n",
        "  def call(self, input):\n",
        "    out = self.conv1(input)\n",
        "    out = self.calc_output_tensor(out)\n",
        "    return out\n",
        "\n",
        "  def calc_output_tensor(self, input):\n",
        "    \n",
        "    \"\"\"Get the Size of the Input Image as a Python-list. The Sizes on the 3 Prediction-Scales are (13x13) (26x26) and (52x52)\"\"\"\n",
        "    grid_pattern_size = (input.shape)[1:3]\n",
        "    grid_pattern_size_list = grid_pattern_size.as_list()\n",
        "\n",
        "    #(f\"Grid_Size_Pattern :  {grid_pattern_size_list}\")\n",
        "    \"\"\"Reshape Input into 2D-Tensor of Cells in the Grid\"\"\"\n",
        "    input = tf.reshape(input, [-1, 3 * grid_pattern_size_list[0] * grid_pattern_size_list[1], 8])\n",
        "    \"\"\"Split the feature map by the last Axis into the different Values per Cell\"\"\"\n",
        "    center_coordinates, width_Length, confidence, classes = tf.split(input, [2, 2, 1, 3], axis=-1)\n",
        "    \"\"\"The Strides for the different Scales correspond to the Divisor of the Scale Size by the Image Size. E.g. for (13,13)-Scale the Divisor would be 412/scale = 13, so 32 \"\"\"\n",
        "    strides = (self.image_size[0] // grid_pattern_size_list[0], self.image_size[1] // grid_pattern_size_list[1])\n",
        "    #(f\"Output von Strides: {strides}\")\n",
        "    \"\"\"Create a Meshgrid equal to the size of the Input Shape, e.g. (13,13)\"\"\"\n",
        "    grid_x_axis = tf.range(grid_pattern_size_list[0], dtype = tf.float32)\n",
        "    grid_y_axis = tf.range(grid_pattern_size_list[1], dtype = tf.float32)\n",
        "    offset_x, offset_y = tf.meshgrid(grid_x_axis, grid_y_axis)\n",
        "  \n",
        "    \"\"\"Reshape the Grids into \"\"\"\n",
        "    offset_x = tf.reshape(offset_x, (-1, 1))\n",
        "    offset_y = tf.reshape(offset_y, (-1, 1))\n",
        "\n",
        "    \"\"\"Concatenate the 2 Grids\"\"\"\n",
        "    x_y_offset = tf.concat([offset_x, offset_y], axis=-1)\n",
        "    \"\"\"Replicates the Tensor\"\"\"\n",
        "    x_y_offset = tf.tile(x_y_offset, [1, 3])\n",
        "    x_y_offset = tf.reshape(x_y_offset, [1, -1, 2])\n",
        " \n",
        "    \"\"\"\n",
        "    For the Shape (13,13) the Meshgrid looks the following way:\n",
        "    [[[ 0  0]\n",
        "      [ 0  0]\n",
        "      [ 0  0]\n",
        "      ...\n",
        "      [12 12]\n",
        "      [12 12]\n",
        "      [12 12]]]\n",
        "    \n",
        "    Essentially, for each normalized Center Coordinate, the Offset on the 13x13 Grid is Added (remember: There are 3 Bounding-Boxes per Grid-Cell with 2 Coordinates). \n",
        "    We Multiply this Value by the Stride (Scale 1: (32,32) Scale 2: (16,16) Scale 3: (8,8)) to get the Center Coordinates in our Input Size \n",
        "    \n",
        "    \"\"\"\n",
        "    \"\"\"Center Coordinates are between 0 and 1 after Sigmoid-Activation\"\"\"\n",
        "    center_coordinates = tf.nn.sigmoid(center_coordinates)\n",
        "    center_coordinates = (center_coordinates + x_y_offset) * strides\n",
        "  \n",
        "    \"\"\"Expands the Anchors into one Anchor-Triple for each Grid Cell, resulting in 13*13*3 = 507 Anchor Boxes for each Image (For Scale 13x13)\"\"\"\n",
        "\n",
        "    anchor = tf.tile(self.anchors, [grid_pattern_size_list[0] * grid_pattern_size_list[1], 1])\n",
        "    \"\"\"Calculate the Bounding Boxes width and length for the current Scale, given a normalized Input of Width and Length\"\"\"\n",
        "    width_Length = width_Length * tf.cast(anchor, tf.float32)\n",
        "\n",
        "    \"\"\"Apply Activation-Function on the other Parameters (Confidence-Score and Classes)\"\"\"\n",
        "    confidence = tf.nn.sigmoid(confidence)\n",
        "   \n",
        "    classes = tf.nn.softmax(classes)\n",
        "\n",
        "    \"\"\"Re-concatenate the Tensor before Output\"\"\"\n",
        "    inputs = tf.concat([center_coordinates, width_Length, confidence, classes], axis=-1)\n",
        "\n",
        "    return inputs\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "onF_OFX-E9Tt"
      },
      "outputs": [],
      "source": [
        "def calculate_bounding_box_coordinates(input):\n",
        "\n",
        "  \"\"\"Split the Tensor\"\"\"\n",
        "  center_coordinate_x,center_coordinate_y, width, length, confidence, classes = tf.split(input, [1, 1, 1, 1, 1, -1], axis=-1)\n",
        "\n",
        "  \"\"\"Calculate the Boxes\"\"\"\n",
        "\n",
        "  top_left_x = center_coordinate_x - width / 2\n",
        "  top_left_y = center_coordinate_y - length /2\n",
        "  bottom_right_x = center_coordinate_x + width / 2\n",
        "  bottom_right_y = center_coordinate_y + length / 2\n",
        "\n",
        "\n",
        "\n",
        "  \"\"\"Reconcatenate the Tensor\"\"\"\n",
        "  box = tf.concat([top_left_x, top_left_y, bottom_right_x, bottom_right_y, confidence, classes], axis = -1)\n",
        "\n",
        "  return box\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "NsKoiZEYAGaP"
      },
      "outputs": [],
      "source": [
        "\"\"\"Performs non-max suppression\n",
        "INPUT SHAPE: ([top_left_x, top_left_y, bottom_right_x, bottom_right_y, confidence, classes])\"\"\"\n",
        "def non_max_suppression(inputs, max_output_size, iou_threshold, confidence_threshold):#\n",
        "    \"\"\"\n",
        "    Parameter:\n",
        "      inputs: Input Tensor of INPUT SHAPE\n",
        "      max_output_size: Maximal Amount of Tensors Non-max-Suppression outputs\n",
        "      iou_threshold: Non-Max-Suppression performs Intersection-of-Union on the Input Bounding Boxes. The Parameter acts as a Threshold for the maximum Overlap of the Bounding Boxes\n",
        "      Confidence_threshold: Probability Vector of the Objectness Score i.e. the Probability of the presence of an Object in the Bounding-Box\n",
        "    Returns:\n",
        "      A Tensor of Shape (Output_amount_of_non_max_suppression, 8), that represents the chosen Bounding Boxes and their Coordinates, Confidence and Class Probabilities. \n",
        "      \n",
        "    \"\"\"\n",
        "\n",
        "    \"\"\"Unstack the Batch\"\"\"\n",
        "    batch = tf.unstack(inputs)\n",
        " \n",
        "    boxes_dicts = []\n",
        "    \"\"\"Iterate the Boxes in the Batch\"\"\"\n",
        "    for boxes in batch:\n",
        "       # (f\"Die Boxen haben den Shape am Anfang: {boxes.shape}\")\n",
        "        \"\"\"Filter out the Boxes, that have a confidence lower than our Threshold\"\"\"\n",
        "        boxes = tf.boolean_mask(boxes, boxes[:, 4] > confidence_threshold)\n",
        "        \"\"\"Split the Boxes for Input into Non-Max-Suppression\"\"\"\n",
        "        boxes_coords, boxes_conf_scores, c1, c2, c3= tf.split(boxes,[4, 1, 1, 1, -1],axis=-1)\n",
        "        boxes_conf_scores = tf.reshape(boxes_conf_scores, [-1])\n",
        "        indices = tf.image.non_max_suppression(boxes_coords,boxes_conf_scores, max_output_size, iou_threshold)\n",
        "        \"\"\"Get Bounding Boxes at Indices returned by Non-Max-Suppression\"\"\"       \n",
        "        boxes = tf.gather(boxes, indices)\n",
        "  \n",
        "\n",
        "\n",
        "    return boxes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "djvWCVic92jT"
      },
      "outputs": [],
      "source": [
        "\"\"\"Final Model of Yolo_V3, combining all Previous Modules\"\"\"\n",
        "\n",
        "class yolo_v3(tf.keras.models.Model):\n",
        "\n",
        "  def __init__(self):\n",
        "    super(yolo_v3,self).__init__()\n",
        "\n",
        "    #Layer Structure\n",
        "    self.darknet = darknet53()\n",
        "    \n",
        "    \"\"\"Route1 with Convolution (13,13)\"\"\"\n",
        "    self.yolo_conv_route1 = yolo_conv_block(512)\n",
        "    self.detection_route1 = yolo_detection_layer(anchors = anchor[0:3])\n",
        "\n",
        "    \"\"\"Route with Convolution (26,26)\"\"\"\n",
        "    self.conv_route2 = Conv_Block(256, 1, 1)\n",
        "\n",
        "    self.concat_route2 = tf.keras.layers.Concatenate(axis = 3)\n",
        "    self.yolo_block_route2 = yolo_conv_block(256)\n",
        "    self.detection_route2 = yolo_detection_layer(anchors = anchor[3:6])\n",
        "  \n",
        "    \"\"\"Route with Convolution (52,52)\"\"\"\n",
        "    self.conv_route3 = Conv_Block(128, 1, 1)\n",
        " \n",
        "    self.concat_route3 = tf.keras.layers.Concatenate(axis = 3)\n",
        "    self.yolo_block_route3 = yolo_conv_block(128)\n",
        "    self.detection_route3 = yolo_detection_layer(anchors = anchor[6:9])\n",
        "\n",
        "  def call(self, input):\n",
        "  \n",
        "    \"\"\"Darknet Feature-Extraction\"\"\"\n",
        "    route1, route2, route3 = self.darknet(input)\n",
        "   \n",
        "    \"\"\"Route1\"\"\"\n",
        "    output_for_detection_r1, reroute_route2 = self.yolo_conv_route1(route1)\n",
        "    scale1_detection_output = self.detection_route1(output_for_detection_r1)\n",
        "\n",
        "    \"\"\"Route2\"\"\"\n",
        "    reroute_route2 = self.conv_route2(reroute_route2)\n",
        "    \n",
        "    size_route2 = route2.shape.as_list()\n",
        "    \"\"\"Upscale the Reroute of Route 1\"\"\"\n",
        "    reroute_route2 = tf.image.resize(reroute_route2,size_route2[1:3], method = tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
        "    \"\"\"Concatenate the Darknet-Output for Route 2 and the Reroute from Route1\"\"\"\n",
        "    route2 = self.concat_route2([route2, reroute_route2])\n",
        "    output_for_detection_r2, reroute_route3 = self.yolo_block_route2(route2)\n",
        "    scale2_detection_output = self.detection_route2(output_for_detection_r2)\n",
        "    \n",
        "    \"\"\"Route3 - Works in the same way as Route 2\"\"\"\n",
        "    reroute_route3 = self.conv_route3(reroute_route3)\n",
        "    \n",
        "    size_route3 = route3.shape.as_list()\n",
        "\n",
        "    reroute_route3 = tf.image.resize(reroute_route3,size_route3[1:3], method = tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
        "\n",
        "    route3 = self.concat_route2([route3, reroute_route3])\n",
        "    output_for_detection_r3, _ = self.yolo_block_route3(route3)\n",
        "    scale3_detection_output = self.detection_route3(output_for_detection_r3)\n",
        "    \"\"\"Concatenate the Bounding-Boxes from the 3 Scales\"\"\"\n",
        "    bounding_boxes = tf.concat([scale1_detection_output, scale2_detection_output, scale3_detection_output], axis = 1)\n",
        "    \"\"\"Calculate the Box-Coordinates\"\"\"\n",
        "    bounding_boxes = calculate_bounding_box_coordinates(bounding_boxes)\n",
        "    \"\"\"Perform non-max-suppression\"\"\"\n",
        "    output = non_max_suppression(bounding_boxes, 20, 0.5, 0.5)\n",
        "  \n",
        "    #(output)\n",
        "    return output\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "r5Jn7SE__vjn"
      },
      "outputs": [],
      "source": [
        "def train_step(model, input, target_c, target_bbox, optimizer):\n",
        "\n",
        "\n",
        "  with tf.GradientTape() as tape:\n",
        "    \n",
        "    prediction = model(input)\n",
        "   # (prediction)\n",
        " \n",
        "\n",
        "    loss = yolo_loss(prediction, target_c, target_bbox)\n",
        "  \n",
        "    gradients = tape.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "  \n",
        "  return loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "Vp7s8BUc8lao"
      },
      "outputs": [],
      "source": [
        "def yolo_loss(input, target_classification, target_bbox):\n",
        "  \"\"\"\n",
        "  Parameters:\n",
        "    input: The Input Tensor with Shape ([top_left_x, top_left_y, bottom_right_x, bottom_right_y, confidence, classes , ...])\n",
        "    target_classification: One-hot-encoded Target \n",
        "    target_bbox: Target Bounding-Box of Shape (xmin, ymin, xmax, ymax) \n",
        "  \"\"\"\n",
        "  total_loss_huber = []\n",
        "  \"\"\"Split the Input\"\"\"\n",
        "  top_left_x, top_left_y, bottom_right_x, bottom_right_y, confidence, class1, class2, class3 = tf.split(input, [1, 1, 1, 1, 1, 1 , 1,-1], axis=-1)\n",
        "\n",
        "  \"\"\"Concatenate the Class Predictions into a Tensor usable in Categorical Crossentropy\"\"\"\n",
        "  class_predictions = tf.concat([class1,class2,class3], axis = -1)\n",
        "  \"\"\"Calculate the Huber-Loss and take the Mean over all Bounding Boxes(because it is less sensitive to extrem values than Mean-Squared-Error).  \"\"\"\n",
        "  huber_loss=tf.keras.losses.Huber()\n",
        "\n",
        "  top_left_x_loss = tf.reduce_mean(huber_loss(target_bbox[0], top_left_x))\n",
        "  top_left_y_loss = tf.reduce_mean(huber_loss(target_bbox[1], top_left_y))\n",
        "  bottom_right_x_loss = tf.reduce_mean(huber_loss(target_bbox[2], bottom_right_x))\n",
        "  bottom_right_y_loss = tf.reduce_mean(huber_loss(target_bbox[3], bottom_right_y))\n",
        "    \n",
        "  huber_loss = tf.reduce_mean([top_left_x_loss, top_left_y_loss, bottom_right_x_loss, bottom_right_y_loss])\n",
        "\n",
        "  \"\"\"Reshape the Target into [Bounding_Box_Amount] of Predictions\"\"\"\n",
        "  class_loss = 0\n",
        "  if class_predictions.shape[0] != 0:\n",
        "    target_classification = tf.expand_dims(target_classification, -1)#\n",
        "    target_classification = tf.repeat(target_classification, class_predictions.shape[0], axis = -1)\n",
        "    target_classification = tf.transpose(target_classification)\n",
        "    \"\"\"Compute Cross-Entropy\"\"\"\n",
        "    #print(target_classification)\n",
        "    #print(class_predicitions)\n",
        "  \n",
        "    class_loss = tf.keras.metrics.categorical_crossentropy(target_classification,class_predictions)\n",
        "   \n",
        "    class_loss = tf.reduce_mean(class_loss)\n",
        "  \"\"\"Scaling the different Losses to give some extra weight to the Classification-Loss\"\"\"\n",
        " \n",
        "  scaling_coord_loss = 0.01\n",
        "  scaling_category_loss = 5\n",
        "  \"\"\"Add and Return the Losses.\"\"\"\n",
        "  total_loss = class_loss * scaling_category_loss + huber_loss * scaling_coord_loss\n",
        "  #print(f\"Class_loss : {class_loss}\")\n",
        "  #print(f\"Huber_loss : {huber_loss}\")\n",
        "  print(f\"Total_loss : {total_loss}\")\n",
        "  return total_loss\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#yolo_loss(None, None, )"
      ],
      "metadata": {
        "id": "6V7gMp-zKdru"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "id": "jYYjflcKUtYn",
        "outputId": "4d8340e8-90a0-4edf-9a76-531b2b956ce2"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-d44474f051e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;31m#yolo_loss(None, target, bbox)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;31m#x+=1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mtrain_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbbox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0;31m#print(train_loss_step)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-705e80ea156e>\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(model, input, target_c, target_bbox, optimizer)\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m    \u001b[0;31m# (prediction)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1094\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1095\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1096\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1097\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0mbound_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_keras_call_info_injected'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-30-53f4c8f86562>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;34m\"\"\"Darknet Feature-Extraction\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mroute1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroute2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroute3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdarknet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;34m\"\"\"Route1\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1094\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1095\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1096\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1097\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0mbound_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_keras_call_info_injected'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    985\u001b[0m       \u001b[0;31m# If we did not create any variables the trace we have is good enough.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    986\u001b[0m       return self._concrete_stateful_fn._call_flat(\n\u001b[0;32m--> 987\u001b[0;31m           filtered_flat_args, self._concrete_stateful_fn.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    988\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfn_with_cond\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minner_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minner_kwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minner_filtered_flat_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1860\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1861\u001b[0m       flat_outputs = forward_function.call(\n\u001b[0;32m-> 1862\u001b[0;31m           ctx, args_with_tangents, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1863\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1864\u001b[0m       with default_graph._override_gradient_function(  # pylint: disable=protected-access\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "### Hyperparameters\n",
        "num_epochs = 10\n",
        "# Initialize the model.\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "model = yolo_v3()\n",
        "train_loss = []\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"Training\"\"\"\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    epoch_loss = []\n",
        "\n",
        "    for input, target, bbox in ds_train:   \n",
        "      \n",
        "        #yolo_loss(None, target, bbox)\n",
        "        #x+=1\n",
        "        train_loss_step = train_step(model, input, target, bbox, optimizer)\n",
        "        #print(train_loss_step)\n",
        "   \n",
        "        epoch_loss.append(train_loss_step)\n",
        "    train_loss.append(tf.reduce_mean(epoch_loss))\n",
        "\n",
        "    print(train_loss[-1])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "INAtmpiaDVIN"
      },
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Project_FaceMask.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}