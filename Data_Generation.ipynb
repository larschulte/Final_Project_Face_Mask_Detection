{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "data_generation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO4d/0NSFv7by+NJxlYiSy1"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import xml.etree.ElementTree as ET\n",
        "import lxml\n",
        "import os\n",
        "import matplotlib.image as mpimg\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf \n",
        "import numpy as np \n",
        "import cv2"
      ],
      "metadata": {
        "id": "qcytwrjrwkfG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NVxpdK16wMzX"
      },
      "outputs": [],
      "source": [
        "\"\"\" setting up google drive and defining directories \"\"\"\n",
        "\n",
        "from google.colab import drive\n",
        "MOUNTPOINT = '/content/drive'\n",
        "\n",
        "DATADIR = os.path.join(MOUNTPOINT, 'MyDrive', 'Project_Face_Mask')\n",
        "DATADIR_annotations = os.path.join(DATADIR, 'Annotations')\n",
        "DATADIR_annotations_train = os.path.join(DATADIR_annotations, 'train')\n",
        "DATADIR_annotations_test = os.path.join(DATADIR_annotations, 'test')\n",
        "DATADIR_train = os.path.join(DATADIR, 'train')\n",
        "DATADIR_test = os.path.join(DATADIR, 'test')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.flush_and_unmount()\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJKFA-3ewPi_",
        "outputId": "189ecd9f-a595-4d0d-ea9d-4071b806af2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive not mounted, so nothing to flush and unmount.\n",
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_data(root_dir, annotation_directory, limit):\n",
        "    \"\"\"\n",
        "    method to extract the image data from google drive \n",
        "\n",
        "    Parameters:\n",
        "      root_dir: root dir of the dataset in google drive\n",
        "      annotation_dir: dir where to find the annotations to each image\n",
        "      limit: amount of faces to extract per label\n",
        "\n",
        "    Returns:\n",
        "      img_data: list of imgs (dictionaries)\n",
        "      number_bboxs: number of lines in the new dataset\n",
        "    \"\"\"\n",
        "    \n",
        "    number_bboxs = 0\n",
        "    img_data = []\n",
        "    mask_corr_count = 0\n",
        "    mask_incorr_count = 0\n",
        "    no_mask_count = 0\n",
        "    \n",
        "    for root_d,directories,filenames in os.walk(annotation_directory):\n",
        "            for i, filename in enumerate(filenames):\n",
        "                                    \n",
        "                path = os.path.join(root_d,filename)\n",
        "                root = ET.parse(path).getroot()\n",
        "\n",
        "                if mask_corr_count == limit and mask_incorr_count == limit and no_mask_count == limit:\n",
        "                    return np.array(img_data), number_bboxs\n",
        "                \n",
        "                image_path = os.path.join(root_dir, root[2].text)\n",
        "\n",
        "                try:\n",
        "                  pict = cv2.imread(image_path)\n",
        "                  picture = cv2.resize(pict, (416,416))\n",
        "                except Exception:\n",
        "                  continue\n",
        "    \n",
        "                for obj in root[6:]:\n",
        "                    if obj[0].text == 'unmasked_face' and no_mask_count < limit:\n",
        "                        no_mask_count += 1        \n",
        "                    elif obj[0].text == 'masked_face' and mask_corr_count < limit:\n",
        "                        mask_corr_count += 1                               \n",
        "                    elif obj[0].text == 'incorrectly_masked_face' and mask_incorr_count < limit:\n",
        "                        mask_incorr_count += 1\n",
        "                    else:\n",
        "                        break\n",
        "                        \n",
        "                    img = {} \n",
        "                    \n",
        "                    img[\"img\"] = picture \n",
        "                    img[\"size\"] = np.array([float(elem.text) for elem in root[4]])\n",
        "\n",
        "                    \"\"\" set the label \"\"\"\n",
        "                    if obj[0].text == 'unmasked_face': \n",
        "                        img[\"label\"] = 0\n",
        "                    elif obj[0].text == 'masked_face': \n",
        "                        img[\"label\"] = 1\n",
        "                    else:\n",
        "                        img[\"label\"] = 2\n",
        "                    \n",
        "                    boxs = []\n",
        "\n",
        "                    \"\"\" resizing the bounding boxes relative the new image size \"\"\"\n",
        "                    try:\n",
        "                        boxs.append(int(float(obj[6][0].text)/img[\"size\"][0]*416))\n",
        "                        boxs.append(int(float(obj[6][1].text)/img[\"size\"][1]*416))\n",
        "                        boxs.append(int(float(obj[6][2].text)/img[\"size\"][0]*416))\n",
        "                        boxs.append(int(float(obj[6][3].text)/img[\"size\"][1]*416))\n",
        "                    except OverflowError as e:\n",
        "                        print(str(e))\n",
        "                        break\n",
        "                    \n",
        "                    img[\"boxs\"] = boxs\n",
        "                    \n",
        "                    number_bboxs += 1\n",
        "                    img_data.append(img)\n",
        "        \n",
        "                \n",
        "    return np.array(img_data), number_bboxs"
      ],
      "metadata": {
        "id": "QZljp6hwwWdM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gen_ds(img_data):\n",
        "    \"\"\" generation of the dataset based on the extracted data \"\"\"\n",
        "    print(img_data)\n",
        "    labels = [img['label'] for img in img_data[0]]\n",
        "    boxs = [img['boxs'] for img in img_data[0]]\n",
        "\n",
        "    boxs = tf.ragged.constant(boxs)\n",
        "    boxs = tf.data.Dataset.from_tensor_slices(boxs)\n",
        "\n",
        "    labels= tf.ragged.constant(labels)\n",
        "    labels = tf.data.Dataset.from_tensor_slices(labels)\n",
        "\n",
        "    imgs = tf.data.Dataset.from_tensor_slices([i['img'] for i in img_data[0]])\n",
        "\n",
        "    ds = tf.data.Dataset.zip((imgs, labels, boxs))\n",
        "\n",
        "    \n",
        "    return ds\n"
      ],
      "metadata": {
        "id": "5KxpbUHiwa-B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_data_train = get_data(DATADIR_train, DATADIR_annotations_train, 1000)\n",
        "ds_train = gen_ds(img_data_train)\n",
        "\n",
        "\"\"\" \n",
        "cannot be executed because the memory in google drive was exhausted and we \n",
        "needed to delete it \n",
        "\"\"\"\n",
        "\n",
        "\"\"\"img_data_test = get_data(DATADIR_test, DATADIR_annotations_test, 300)\n",
        "ds_test = gen_ds(img_data_test)\"\"\"\n"
      ],
      "metadata": {
        "id": "UFk0mGdNwgXe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}